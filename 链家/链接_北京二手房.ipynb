{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "#设置列表页URL的固定部分\n",
    "url='http://bj.lianjia.com/ershoufang/'\n",
    "#设置页面页的可变部分\n",
    "page=('pg')\n",
    "#此外，还需要在很http请求中设置一个头部信息，否则很容易被封。头部信息网上有很多现成的，也可以使用httpwatch等工具来查看。具体细节按照具体情况进行调整。\n",
    "\n",
    "#设置请求头部信息\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "'Accept':'text/html;q=0.9,*/*;q=0.8',\n",
    "'Accept-Charset':'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "'Accept-Encoding':'gzip',\n",
    "'Connection':'close',\n",
    "'Referer':'http://www.baidu.com/link?url=_andhfsjjjKRgEWkj7i9cFmYYGsisrnm2A-TN3XZDQXxvGsM9k9ZZSnikW2Yds4s&amp;wd=&amp;eqid=c3435a7d00006bd600000003582bfd1f'\n",
    "}\n",
    "#使用for循环生成1-100的数字，转化格式后与前面的URL固定部分拼成要抓取的URL。这里我们设置每两个页面间隔0.5秒。抓取到的页面保存在html中。\n",
    "\n",
    "#循环抓取列表页信息\n",
    "for i in range(1,100):\n",
    "    if i==1:\n",
    "        i=str(i)\n",
    "        a=(url+page+i+'/')\n",
    "        r=requests.get(url=a,headers=headers)\n",
    "        html=r.content\n",
    "    else:\n",
    "        i=str(i)\n",
    "        a=(url+page+i+'/')\n",
    "        r=requests.get(url=a,headers=headers)\n",
    "        html2=r.content\n",
    "        html=html+html2\n",
    "    #每隔0.5秒\n",
    "    time.sleep(0.5)\n",
    "#页面抓取完成后无法直接阅读和进行数据提取，还需要进行页面解析。我们使用BeautifulSoup对页面进行解析。变成我们在浏览器查看源代码中看到的样子。\n",
    "\n",
    "#解析抓取的页面内容\n",
    "lj=BeautifulSoup(html,'html.parser')\n",
    "\n",
    "#解析抓取的页面内容\n",
    "lj = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "#把页面div标签中class=priceinfo的部分提取出来\n",
    "price=lj.find_all('div',attrs={'class':'priceInfo'})\n",
    "tp = []\n",
    "for a in price:\n",
    "    totalPrice = a.span.string\n",
    "    tp.append(totalPrice)\n",
    "#提取房源信息\n",
    "houseInfo=lj.find_all('div',attrs={'class':'houseInfo'})\n",
    "\n",
    "hi=[]\n",
    "for b in houseInfo:\n",
    "    house=b.get_text()\n",
    "    hi.append(house)\n",
    "#提取房源关注度\n",
    "followInfo=lj.find_all('div',attrs={'class':'followInfo'})\n",
    "fi=[]\n",
    "for c in followInfo:\n",
    "    follow=c.get_text()\n",
    "    fi.append(follow)\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "house=pd.DataFrame({'totalprice':tp,'houseinfo':hi,'followinfo':fi})\n",
    "print (house.head())\n",
    "houseinfo_split = pd.DataFrame((x.split('|') for x in house.houseinfo),index=house.index,columns=['xiaoqu','huxing','mianji','chaoxiang','zhuangxiu','dianti'])\n",
    "print (houseinfo_split.head())\n",
    "#将分列结果接回原始数据表\n",
    "house=pd.merge(house,houseinfo_split,right_index=True,left_index=True)\n",
    "#对房源关注度进行分列\n",
    "followinfo_split = pd.DataFrame((x.split('/') for x in house.followinfo),index=house.index,columns=['guanzhu','daikan','fabu'])\n",
    "#将分列后的关注度信息拼接回原数据表\n",
    "house=pd.merge(house,followinfo_split,right_index=True, left_index=True)\n",
    "print(house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}